{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n##Get the web page content\n\nDEBUG = True;",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging\nimport smtplib\n\nlogging.basicConfig(filename='execution.log', level=logging.DEBUG, \n                    format='%(asctime)s %(levelname)s %(name)s %(message)s')\nlogger=logging.getLogger(__name__)\n\n#try:\n#    1/0\n#except ZeroDivisionError as err:\n#    logger.error(err)\n\n\n#EMAIL OK ######################################\nusername = str('perell2020@gmail.com')  \npassword = str('Zurich46744113')  \nserver = \"smtp.gmail.com\"\nsent_from = \"perell2020@gmail.com\"\nto = \"pcll1m@yahoo.es\"\nemail_body = \"Error:\"\nemail_subject = \"Problem executing scraping activity\"\n\n# send email\ndef send_email(user, pwd, recipient, subject, body):\n    FROM = user\n    TO = recipient if isinstance(recipient, list) else [recipient]\n    SUBJECT = subject\n    TEXT = body\n\n    # Prepare actual message\n    message = \"\"\"From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\n    \"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\n    try:\n        server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n        server.ehlo()\n        server.starttls()\n        server.login(user, pwd)\n        server.sendmail(FROM, TO, message)\n        server.close()\n        print ('successfully sent the mail')\n    except:\n        print (\"failed to send mail\")\n        logger.error(\"failed to send mail\")\n\n\ndef reporterror(errordesc):\n    logger.error(errordesc)    \n    send_email('perell2020@gmail.com','Zurich46744113','pcll1m@yahoo.es','2019-nCov Python SCRAPE_BNO Error on exec',errordesc)",
      "execution_count": 66,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Libray\nimport requests\nfrom bs4 import BeautifulSoup as bs\nimport datetime\nimport dateutil.parser\n\n#url\nurl = \"https://bnonews.com/index.php/2020/02/the-latest-coronavirus-cases/\"\ndiscardlist = ['MAINLAND CHINA','INTERNATIONAL','REGIONS','']\n\n\n#return empty sring\ndef emptystr(s):\n    if s is None:\n        return ''\n    return str(s)\n\n#Control request access\ndef request_url(objurl):\n    #request\n    headers = {\n    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36'}\n    try:\n        # your logic is here\n        response = requests.get(url, headers=headers, timeout=5)\n        if response.status_code!=200:\n            print(\"Wrong status code: \" + response.status_code)\n            return \"Error status code\"\n        #Access the full response as text (get the HTML of the page in a big string)\n        #print (response.text)\n        #Look for a specific substring of text within the response\n        if \"blocked\" in response.text:\n            print (\"we've been blocked\")\n            return \"Error blocked\"\n    except requests.ConnectionError as e:\n        print(\"OOPS!! Connection Error. Make sure you are connected to Internet. Technical Details given below.\\n\")\n        print(str(e))\n        return \"Error conn. error\"\n    except requests.Timeout as e:\n        print(\"OOPS!! Timeout Error\")\n        print(str(e))\n        return \"Error timeout\"\n    except requests.RequestException as e:\n        print(\"OOPS!! General Error\")\n        print(str(e))\n        return \"Error gral. error\"    \n    except KeyboardInterrupt:\n        print(\"Someone closed the program\")\n        return \"Error someone closed the program\"\n    return response.text\n        \n        \n#scrape function\ndef scrape (html_content):\n    try:\n        doc = ''\n        table_doc = bs(html_content, 'html.parser')\n        #get the urlfinal\n        urlfinal = '# source: BNO @ ' + emptystr(table_doc.find_all(\"link\", {\"rel\" : \"canonical\"})[0].get('href')) + '\\n'\n        #print (urlfinal)\n        #update\n        update = emptystr(table_doc.find_all('em')[0].string).replace('Last update:','') + '\\n'\n        if update !='':\n            #process date toi the right format\n            date_time_str = update\n            date_object = dateutil.parser.parse(date_time_str)\n            #INFOdate_string = ' 8 February 2020 at 5:17 p.m. ET\\n' does not match format '%d %B %Y %I:%M%p''\n            #date_object = datetime.datetime.strptime(date_time_str, '%d %B %Y %I:%M%p')\n            #print(\"DATE \" + str(date_object))\n            #date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n            #print('Date-time:', date_time_obj)\n        update = '# update:' + str(date_object) + ' ET\\n'    \n        # place|confirmed_cases|deaths|notes|sources\n        place = '# place|confirmed_cases|deaths|notes|sources\\n' \n        doc = urlfinal + update + place\n        firstPass = True\n        # parsing html content\n        for tables in table_doc.find_all('table'):\n            for tr in tables.find_all('tr'):\n                #ATTENTION USE .TEXT WHEN SPECIAL CHARS\n                rowControl = emptystr(tr.find_all('td')[0].text)\n                if rowControl not in discardlist:\n                    line = ''\n                    #control hubei\n                    if rowControl.find(\"Hubei\") != -1: \n                        #in 'Hubei': \n                        rowControl = 'Hubei'\n                    if (firstPass and rowControl in 'TOTAL'):\n                        rowControl = 'China'\n                        line = rowControl + '|' + emptystr(tr.find_all('td')[1].string) + '|' + emptystr(tr.find_all('td')[2].string) + '|' + emptystr(tr.find_all('td')[3].string) + '\\n'\n                    if (firstPass and rowControl not in 'TOTAL'):\n                        rowControl =  rowControl.replace('province','')\n                        source = emptystr(tr.find_all('td')[4].find('a'))\n                        if source!=\"\":\n                            source = emptystr(tr.find_all('td')[4].find('a').get('href'))\n                        line = rowControl + '|' + emptystr(tr.find_all('td')[1].string) + '|' + emptystr(tr.find_all('td')[2].string) + '|' + emptystr(tr.find_all('td')[3].string) + '|' +  source + '\\n'\n                    if (firstPass==False and rowControl not in 'TOTAL'):\n                        source = emptystr(tr.find_all('td')[4].find('a'))\n                        if source!=\"\":\n                            source = emptystr(tr.find_all('td')[4].find('a').get('href'))\n                        line = rowControl + '|' + emptystr(tr.find_all('td')[1].string) + '|' + emptystr(tr.find_all('td')[2].string) + '|' + emptystr(tr.find_all('td')[3].string) + '|' +  source + '\\n'\n                    doc = doc + line \n            firstPass = False         \n        #print(doc)\n        return(doc)\n    except AttributeError as e:\n        return(\"ERROR \" + str(e))\n    ",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#OUTPUT MODEL\n# source: BNO @ https://bnonews.com/index.php/2020/01/the-latest-coronavirus-cases/\n# update: 2020-01-24 14:55:00 CST\n# place|confirmed_cases|deaths|notes|sources\n#Hubei|729|39|100 serious/57 critical|http://wjw.hubei.gov.cn/fbjd/dtyw/202001/t20200125_2014854.shtml\n#Guangdong|53|0|12 serious, 3 critical|http://wsjkw.gd.gov.cn/zwyw_yqxx/content/post_2878949.html\n#Zhejiang|43|0|6 serious|https://www.zjwjw.gov.cn/art/2020/1/24/art_1202101_41855167.html",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#process from file\ndef scrapefromfile(fname):\n    try:\n        f = open(fname, 'rb')\n    except OSError:\n        print (\"Could not open/read file:\", fname)\n        sys.exit()\n\n    with f:\n        #reader = csv.reader(f)\n        #for row in reader:\n        #    pass #do stuff here\n        data = f.read()\n    \n    if data[0:4] !=\"Error\":\n        print ('Got response')\n        scrape(data)\n    else:\n        print('Problem accessing: Error code' + data)\n\n#scrapefromfile(\"bno_6.html\")\n\n#processfromweb\ndef scrapefromweb(url):\n    #If page available proceed with scrape\n    data = request_url(url)\n    if data[0:4] !=\"Error\":\n        print ('Got response')\n        output = scrape(data)\n        if output[0:4] !=\"Error\":\n            print('Scraping content went well')\n        else:\n            print('Problem Scraping: Error' + output)\n            reporterror('Problem Scraping: Error' + output)\n    else:\n        print('Problem accessing: Error code' + data)\n        reporterror('Problem Scraping: Error' + output)\n    return output\n                    \n        \n                    \ndatafile = \"data.txt\"\n                    \n\n#process from file\ndef readfile(fname):\n    try:\n        f = open(fname, 'rb')\n    except OSError:\n        print (\"Could not open/read file:\", fname)\n        reporterror('Could not open/read file:', fname)\n        #sys.exit()\n        datafile =''\n    with f:\n        datafile = f.read()\n    return datafile\n                    \n#append to file\ndef appendtofile(fname,datatowrite):\n    if DEBUG:\n        return True\n    try:\n        f = open(fname, 'a')\n    except OSError:\n        print (\"Could not open/read file:\", fname)\n        reporterror('Could not append to file:', fname)\n        #sys.exit()\n        return False\n    with f:\n        print('APPEND')\n        n = f.write(datatowrite)\n        f.close()\n        return True\n        \n                                                  \n#def testIfNeedScraping:\ndef doweneedtoscrape():\n    #open file                \n    content = readfile(datafile)              \n    #latest getdate data\n    #dataurl = 'https://raw.githubusercontent.com/perell2014/data_2019ncov/master/data.txt'\n    #response = requests.get(dataurl)\n    #content = response.text\n    blocks = str(content).split(\"update:\")\n    if (len(blocks)>0):\n        latestDate = blocks[len(blocks)-1][0:19]\n        date_latestDate = dateutil.parser.parse(latestDate)\n        #print (latestDate)\n        #get last update from the scrapping               \n        scrapedcontent = scrapefromweb(url)\n        if scrapedcontent[0:4] !=\"Error\":\n            blocks = scrapedcontent.split(\"update:\")\n            if (len(blocks)>0):\n                latestwebDate = blocks[len(blocks)-1][0:19]\n                date_latestwebDate = dateutil.parser.parse(latestwebDate)\n                #print (latestwebDate)\n                #CMP DATA\n                if (date_latestDate < date_latestwebDate):\n                    if appendtofile(datafile,scrapedcontent):\n                        logger.info('Successfull Append of the data file extraction with the last update:' + latestDate + \" web last update: \" + latestwebDate)\n                        print('Successfull Append of the data file extraction with the last update:' + latestDate + \" web last update: \" + latestwebDate)\n                        if DEBUG:\n                            print(scrapedcontent)\n                else:\n                    logger.info(\"No need to scrape data file last date:\" + latestDate + \" web last update:\" + latestwebDate)\n            else:\n                reporterror('No update section found in the scraping web')\n        else:\n            reporterror('No update date found in the data file!!')\n    \n    \n#Execution\nif __name__ == \"__main__\":\n    logger.info(\"Sarting process SCRAPE_NBO\")\n    doweneedtoscrape()\n         ",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Got response\nScraping content went well\nSuccessfull Append of the data file extraction with the last update:2020-02-08 17:17:00 web last update: 2020-02-08 20:02:00\n# source: BNO @ https://bnonews.com/index.php/2020/02/the-latest-coronavirus-cases/\n# update:2020-02-08 20:02:00 ET\n# place|confirmed_cases|deaths|notes|sources\nHubei|27,100|780|4,093 serious, 1,154 critical|http://wjw.hubei.gov.cn/fbjd/dtyw/202002/t20200209_2021930.shtml\nGuangdong |1,095|1|86 serious, 38 critical|http://wsjkw.gd.gov.cn/zwyw_yqxx/content/post_2888192.html\nZhejiang |1,048|0|53 serious, 25 critical|https://www.zjwjw.gov.cn/art/2020/2/8/art_1202101_41890388.html\nHenan |981|4|58 serious, 28 critical|https://m.weibo.cn/status/4469615763854619\nHunan |803|1|56 serious|https://m.weibo.cn/detail/4469739122390609\nAnhui |733|0|6 critical|http://wjw.ah.gov.cn/news_details_54672.html\nJiangxi |698|0|61 serious |http://hc.jiangxi.gov.cn/doc/2020/02/08/138433.shtml\nChongqing|428|2|31 serious, 17 critical|http://wsjkw.cq.gov.cn/tzgg/20200208/252719.html\nJiangsu |439|0|4 serious, 2 critical|https://m.weibo.cn/status/4469614027601267\nShandong |416|0|25 serious, 7 critical|https://m.weibo.cn/detail/4469710214671587\nSichuan |364*|1|20 critical|https://m.weibo.cn/status/4469613796748238\nBeijing|315|2|1+ critical|https://m.weibo.cn/detail/4469644544990553\nShanghai|286|1|12 serious, 8 critical|http://wsjkw.sh.gov.cn/xwfb/20200208/28cc33026c754317a3463256024ef5ce.html\nHeilongjiang |295|5|38 serious|http://wsjkw.hlj.gov.cn/index.php/Home/Zwgk/show/newsid/7762/navid/42/stypeid/\nFujian |239|0|12 serious, 8 critical|http://headline.fjtv.net/folder875/2020-02-08/2168529.html\nShaanxi |195|0|1+ serious|http://sxwjw.shaanxi.gov.cn/art/2020/2/8/art_9_67873.html\nGuangxi Region|183|0|7 serious, 8 critical|http://wsjkw.gxzf.gov.cn/zhuantiqu/ncov/ncovyqtb/2020/0208/68542.html\nHebei |195|1|16 serious|http://www.hebwst.gov.cn/index.do?id=397504&templet=content&cid=14\nYunnan |138|0|15 serious, 3 critical|http://www.bjnews.com.cn/feature/2020/02/08/686220.html\nHainan |124|2|13 serious|https://m.weibo.cn/detail/4469618502446670\nShanxi |104|0|6 serious, 6 critical|http://wjw.shanxi.gov.cn/wjywl02/24758.hrh\nLiaoning |103|0|14 serious, 1 critical|https://m.weibo.cn/status/4469706410874349\nTianjin|88|1|32 serious, 5 critical|https://m.weibo.cn/detail/4469647032393927\nGuizhou |89|1|9 serious, 9 critical|http://www.gzhfpc.gov.cn/xwzx_500663/tzgg/202002/t20200208_47776446.html\nGansu |71|1|7 serious, 2 critical|http://wsjk.gansu.gov.cn/single/10910/83839.html\nJilin |69|1|5 serious, 1 critical|https://m.weibo.cn/detail/4469604653292027\nInner Mongolia|52|0||http://wjw.nmg.gov.cn/doc/2020/02/08/291115.shtml\nNingxia Region|45|0|1 serious|http://wsjkw.nx.gov.cn/info/1140/13645.htm\nXinjiang|42|0|9 serious, 2 critical|http://www.xjhfpc.gov.cn/info/1495/18152.htm\nQinghai |18|0|1 serious|https://m.weibo.cn/status/4468903075418422\nTibet|1|0|Stable|http://www.nhc.gov.cn/yjb/s7860/202001/e71bd2e7a0824ca69f87bbf1bef2a3c9.shtml\nUndisclosed|441|7||http://www.nhc.gov.cn/yjb/s7860/202002/4f28ab5ca87d42d284833df3ccc8d45a.shtml\nChina|37,198|811||\nHong Kong|26|1||https://www.chp.gov.hk/files/pdf/enhanced_sur_pneumonia_wuhan_eng.pdf\nTaiwan|17|0|1 recovered|https://www.cdc.gov.tw/Bulletin/Detail/CngpYj-4R7LFxtHUDUK5Vw?typeid=9\nMacau|10|0||https://news.gov.mo/detail/zh-hant/N20BDPAzBd?3\nJapan|89*|0|4 recovered|https://this.kiji.is/598672585603007585?c=39550187727945729\nSingapore|40|0|4 critical, 2 recovered|https://www.moh.gov.sg/news-highlights/details/seven-more-confirmed-cases-of-novel-coronavirus-infection-in-singapore\nThailand|32|0|1 serious, 10 recovered|https://pr.moph.go.th/?url=pr/detail/2/04/138421/\nSouth Korea|25|0|1 recovered|https://en.yna.co.kr/view/AEN20200209000600320\nAustralia|15|0|5 recovered|https://www.health.gov.au/news/coronavirus-update-at-a-glance\nMalaysia|16|0|15 stable, 1 recovered|https://twitter.com/KKMPutrajaya/status/1226065545872592896\nGermany|14|0||https://www.stmgp.bayern.de/presse/aktuelle-informationen-zur-coronavirus-lage-in-bayern-bayerisches-gesundheitsministerium-14/\nUnited States|12|0|3 recovered|https://edition.cnn.com/2020/02/07/us/illinois-coronavirus-patients-discharge/index.html\nVietnam|13|0|3 recovered|https://vietnamnet.vn/vn/suc-khoe/suc-khoe-24h/ca-duong-tinh-virus-corona-thu-13-o-viet-nam-613604.html\nCanada|7|0||https://news.gov.bc.ca/releases/2020HLTH0025-000236\nFrance|11|0|1 serious|https://www.lefigaro.fr/sciences/coronavirus-5-nouveaux-cas-en-france-20200208\nUAE|7|0||https://wam.ae/ar/details/1395302822121\nUnited Kingdom|3|0||https://www.gov.uk/government/news/cmo-confirms-third-case-of-coronavirus-in-england\nPhilippines|3|1||https://www.youtube.com/watch?v=_pIluXrMHCk\nIndia|3|0|Stable|https://www.pib.gov.in/PressReleseDetail.aspx?PRID=1601681\nItaly|3|0|2 serious|https://www.ansa.it/canale_saluteebenessere/notizie/sanita/2020/02/03/coronavirus-accertamenti-su-italiano-alla-cecchignola-_b20da9f2-57a5-4870-978f-23e9c50d6155.html\nRussia|2|0||https://tass.ru/obschestvo/7656549\nNepal|1|0||https://kathmandupost.com/2/2020/01/24/officials-confirm-novel-coronavirus-in-nepali-man-who-returned-from-wuhan-earlier-this-month\nCambodia|1|0|1 recovered|https://twitter.com/VOD_English/status/1221769368180121603\nSri Lanka|1|0|1 recovered|https://www.reuters.com/article/us-health-china-sri-lanka/sri-lanka-confirms-first-case-of-coronavirus-health-official-idUSKBN1ZQ1WF\nFinland|1|0|1 recovered|https://yle.fi/uutiset/osasto/news/finlands_first_coronavirus_patient_released_from_hospital_symptom-free/11193661\nSweden|1|0||https://www.folkhalsomyndigheten.se/nyheter-och-press/nyhetsarkiv/2020/januari/bekraftat-fall-av-nytt-coronavirus-i-sverige/\nSpain|1|0||https://www.antena3.com/noticias/sociedad/confirmado-caso-coronavirus-gomera_202001315e34a9380cf2cfb788f47b07.html\nBelgium|1|0||https://www.info-coronavirus.be/nl/2020/02/04/gerepatrieerde-landgenoot-testte-positief-op-het-nieuwe-coronavirus/\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!git status",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": "On branch master\nYour branch is ahead of 'origin/master' by 5 commits.\n  (use \"git push\" to publish your local commits)\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n\t\u001b[31mmodified:   .ipynb_checkpoints/SCRAPE_BNO-checkpoint.ipynb\u001b[m\n\t\u001b[31mmodified:   ETL.ipynb\u001b[m\n\t\u001b[31mmodified:   SCRAPE_BNO.ipynb\u001b[m\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n\t\u001b[31mexecution.log\u001b[m\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!git add data.txt\n!git add execution.log\n!git add .ipynb_checkpoints/SCRAPE_BNO-checkpoint.ipynb\n!git add .ipynb_checkpoints/ETL-checkpoint.ipynb\n!git add bno_6.html\n!git add data_6_7_8.txt\n!git add SCRAPE_BNO.ipynb\n!git add ETL.ipynb\n!git commit -am \"Last 3\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!cd ~/library\n!git config user.name \"perell2014\"\n!git config user.email \"perell@gmail.com\"\n!git config -l\n!git config push.default simple\n!git push https://perell2014:aaaAAA2014@github.com/perell2014/data_2019ncov.git --all",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}